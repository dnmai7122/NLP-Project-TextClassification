{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3415101,"sourceType":"datasetVersion","datasetId":2058416}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Install & Import Libraries","metadata":{}},{"cell_type":"code","source":"!pip install underthesea","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-13T14:49:33.685342Z","iopub.execute_input":"2025-09-13T14:49:33.686364Z","iopub.status.idle":"2025-09-13T14:49:42.718013Z","shell.execute_reply.started":"2025-09-13T14:49:33.686329Z","shell.execute_reply":"2025-09-13T14:49:42.716486Z"}},"outputs":[{"name":"stdout","text":"Collecting underthesea\n  Downloading underthesea-6.8.4-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from underthesea) (8.2.1)\nCollecting python-crfsuite>=0.9.6 (from underthesea)\n  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from underthesea) (3.9.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from underthesea) (4.67.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from underthesea) (2.32.4)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.5.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.2.2)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from underthesea) (6.0.2)\nCollecting underthesea-core==1.0.4 (from underthesea)\n  Downloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->underthesea) (2024.11.6)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2025.6.15)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.15.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn->underthesea) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nDownloading underthesea-6.8.4-py3-none-any.whl (20.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl (657 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: underthesea-core, python-crfsuite, underthesea\nSuccessfully installed python-crfsuite-0.9.11 underthesea-6.8.4 underthesea-core-1.0.4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport re\nimport string\n\nfrom underthesea import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score\n\nfrom tensorflow import keras\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Embedding, LSTM, Dropout\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T14:49:42.720227Z","iopub.execute_input":"2025-09-13T14:49:42.720712Z","iopub.status.idle":"2025-09-13T14:49:57.344178Z","shell.execute_reply.started":"2025-09-13T14:49:42.720674Z","shell.execute_reply":"2025-09-13T14:49:57.342941Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# 2. Load Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/vietnamese-text-classification-dataset/train.csv', names = ['label', 'content'])\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T14:49:57.345181Z","iopub.execute_input":"2025-09-13T14:49:57.345893Z","iopub.status.idle":"2025-09-13T14:49:57.471827Z","shell.execute_reply.started":"2025-09-13T14:49:57.345854Z","shell.execute_reply":"2025-09-13T14:49:57.470653Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   label                                            content\n0      0                             máy dùng hay bị đơ máy\n1      0  chỉ có dây cáp nguồn không có adapter sao sử d...\n2      0  Chất lượng quá kém Mới dùng được 2 ngày loa ba...\n3      0  Usb tôi vừa mới nhận usb này Rất bực bội vì cá...\n4      2                       Tuyệt vời. Hàng FPT cửa hàng","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>máy dùng hay bị đơ máy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>chỉ có dây cáp nguồn không có adapter sao sử d...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Chất lượng quá kém Mới dùng được 2 ngày loa ba...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Usb tôi vừa mới nhận usb này Rất bực bội vì cá...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Tuyệt vời. Hàng FPT cửa hàng</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T14:49:57.472772Z","iopub.execute_input":"2025-09-13T14:49:57.473052Z","iopub.status.idle":"2025-09-13T14:49:57.506005Z","shell.execute_reply.started":"2025-09-13T14:49:57.473031Z","shell.execute_reply":"2025-09-13T14:49:57.504524Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3040 entries, 0 to 3039\nData columns (total 2 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   label    3040 non-null   int64 \n 1   content  3040 non-null   object\ndtypes: int64(1), object(1)\nmemory usage: 47.6+ KB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# 3. Text Cleaning","metadata":{}},{"cell_type":"code","source":"def clean_text(text: str) -> str:\n    \"\"\"\n    Làm sạch văn bản:\n    - Chuyển thành chữ thường\n    - Loại bỏ URL, domain phổ biến (.com, .net, .org, ...)\n    - Loại bỏ số, ký tự đặc biệt, punctuation\n    - Loại bỏ emoji\n    - Chuẩn hóa khoảng trắng\n    \"\"\"\n    text = str(text).lower()\n\n    # Remove URLs\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', ' ', text)\n\n    # Remove common domain tokens\n    text = re.sub(r'\\b(com|net|org)\\b', ' ', text, flags=re.IGNORECASE)\n\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n\n    # Remove special characters (chỉ giữ chữ, số, dấu cách)\n    text = re.sub(r'[^\\w\\s]', ' ', text)\n\n    # Remove numbers\n    text = re.sub(r'\\d+', ' ', text)\n\n    # Remove underscore\n    text = text.replace('_', ' ')\n\n    # Remove emoji\n    emoji_pattern = re.compile(\n        \"[\" \n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n        u\"\\U00002702-\\U000027B0\"  \n        u\"\\U000024C2-\\U0001F251\"\n        \"]+\", flags=re.UNICODE\n    )\n    text = emoji_pattern.sub('', text)\n\n    # Normalize whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n\n    return text\n\n\ndef preprocessing(df: pd.DataFrame, text_column: str) -> pd.DataFrame:\n    \"\"\"\n    Làm sạch toàn bộ cột văn bản trong DataFrame\n    \"\"\"\n    df[text_column] = df[text_column].astype(str).apply(clean_text)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T14:49:57.509967Z","iopub.execute_input":"2025-09-13T14:49:57.510439Z","iopub.status.idle":"2025-09-13T14:49:57.535228Z","shell.execute_reply.started":"2025-09-13T14:49:57.510409Z","shell.execute_reply":"2025-09-13T14:49:57.533895Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = preprocessing(df, \"content\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T14:49:57.536450Z","iopub.execute_input":"2025-09-13T14:49:57.537694Z","iopub.status.idle":"2025-09-13T14:49:57.763640Z","shell.execute_reply.started":"2025-09-13T14:49:57.537649Z","shell.execute_reply":"2025-09-13T14:49:57.762292Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   label                                            content\n0      0                             máy dùng hay bị đơ máy\n1      0  chỉ có dây cáp nguồn không có adapter sao sử d...\n2      0  chất lượng quá kém mới dùng được ngày loa bass...\n3      0  usb tôi vừa mới nhận usb này rất bực bội vì cá...\n4      2                        tuyệt vời hàng fpt cửa hàng","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>máy dùng hay bị đơ máy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>chỉ có dây cáp nguồn không có adapter sao sử d...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>chất lượng quá kém mới dùng được ngày loa bass...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>usb tôi vừa mới nhận usb này rất bực bội vì cá...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>tuyệt vời hàng fpt cửa hàng</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# 4. Train/Test Split","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    df[\"content\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T14:49:57.764702Z","iopub.execute_input":"2025-09-13T14:49:57.765068Z","iopub.status.idle":"2025-09-13T14:49:57.776634Z","shell.execute_reply.started":"2025-09-13T14:49:57.765036Z","shell.execute_reply":"2025-09-13T14:49:57.775631Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# 5. Classical Machine Learning (SVM + TF-IDF)","metadata":{}},{"cell_type":"code","source":"tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\nX_train_vec = tfidf.fit_transform(X_train)\nX_test_vec = tfidf.transform(X_test)\n\nsvm = SVC(kernel=\"linear\")\nsvm.fit(X_train_vec, y_train)\n\ny_pred = svm.predict(X_test_vec)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred, digits=3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T14:49:57.777758Z","iopub.execute_input":"2025-09-13T14:49:57.778085Z","iopub.status.idle":"2025-09-13T14:50:00.695825Z","shell.execute_reply.started":"2025-09-13T14:49:57.778061Z","shell.execute_reply":"2025-09-13T14:50:00.694669Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8026315789473685\n              precision    recall  f1-score   support\n\n           0      0.784     0.905     0.840       221\n           1      0.710     0.621     0.663       177\n           2      0.899     0.848     0.873       210\n\n    accuracy                          0.803       608\n   macro avg      0.798     0.791     0.792       608\nweighted avg      0.802     0.803     0.800       608\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# 6. Deep Learning with LSTM","metadata":{}},{"cell_type":"code","source":"# Tokenizer\nlist_tokens = [word_tokenize(x) for x in df[\"content\"]]\ntokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(list_tokens)\nseqs = tokenizer.texts_to_sequences(list_tokens)\npadded = pad_sequences(seqs, maxlen=200)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    padded, df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"]\n)\n\n# Model LSTM\ninput_layer = Input(shape=(200,))\nx = Embedding(10000, 128)(input_layer)\nx = LSTM(64)(x)\nx = Dropout(0.5)(x)\noutput = Dense(3, activation=\"softmax\")(x)\n\nmodel = Model(input_layer, output)\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\nearly_stop = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2)\n\nhistory = model.fit(\n    X_train, y_train, validation_split=0.1, epochs=10, batch_size=64,\n    callbacks=[early_stop, reduce_lr]\n)\n\nprint(\"Evaluate:\", model.evaluate(X_test, y_test))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T14:50:00.696951Z","iopub.execute_input":"2025-09-13T14:50:00.697232Z","iopub.status.idle":"2025-09-13T14:51:14.624073Z","shell.execute_reply.started":"2025-09-13T14:50:00.697210Z","shell.execute_reply":"2025-09-13T14:51:14.622740Z"}},"outputs":[{"name":"stderr","text":"2025-09-13 14:50:03.226236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757775003.509206      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757775003.590317      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-09-13 14:50:27.778896: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 184ms/step - accuracy: 0.4301 - loss: 1.0759 - val_accuracy: 0.5738 - val_loss: 0.9135 - learning_rate: 0.0010\nEpoch 2/10\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 174ms/step - accuracy: 0.6169 - loss: 0.8485 - val_accuracy: 0.6434 - val_loss: 0.7171 - learning_rate: 0.0010\nEpoch 3/10\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 167ms/step - accuracy: 0.7368 - loss: 0.5976 - val_accuracy: 0.7582 - val_loss: 0.5939 - learning_rate: 0.0010\nEpoch 4/10\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - accuracy: 0.8550 - loss: 0.4117 - val_accuracy: 0.7869 - val_loss: 0.5648 - learning_rate: 0.0010\nEpoch 5/10\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - accuracy: 0.9235 - loss: 0.2667 - val_accuracy: 0.7746 - val_loss: 0.6402 - learning_rate: 0.0010\nEpoch 6/10\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - accuracy: 0.9390 - loss: 0.1880 - val_accuracy: 0.7869 - val_loss: 0.6625 - learning_rate: 0.0010\nEpoch 7/10\n\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - accuracy: 0.9686 - loss: 0.1129 - val_accuracy: 0.7992 - val_loss: 0.7106 - learning_rate: 5.0000e-04\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.8107 - loss: 0.5151\nEvaluate: [0.5499579906463623, 0.78125]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# !pip install --upgrade transformers\n# !pip install transformers datasets torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import Dataset\nfrom datasets import ClassLabel\n\n# 1. Dataset\nhf_dataset = Dataset.from_pandas(\n    df[[\"content\", \"label\"]].rename(columns={\"label\":\"labels\"})\n)\n\nnum_classes = len(set(df[\"label\"]))\nclass_label = ClassLabel(num_classes=num_classes, names=[str(i) for i in range(num_classes)])\nhf_dataset = hf_dataset.cast_column(\"labels\", class_label)\n\n# 2. Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\ndef tokenize_fn(batch):\n    return tokenizer(batch[\"content\"], padding=\"max_length\", truncation=True, max_length=256)\nhf_dataset = hf_dataset.map(tokenize_fn, batched=True)\nhf_dataset = hf_dataset.train_test_split(test_size=0.2, stratify_by_column=\"labels\")\n\n# 3. Model\nmodel = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels=num_classes)\n\n# 4. Training args\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    report_to=\"none\"   \n)\n\n# 5. Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=hf_dataset[\"train\"],\n    eval_dataset=hf_dataset[\"test\"],\n    processing_class=tokenizer   \n)\n\n# 6. Train\ntrainer.train()\n\n# 7. Evaluate\nprint(trainer.evaluate())\n\n# 8. Predict\ntest_text = \"Sản phẩm này rất tốt và dùng ổn định\"\ninputs = tokenizer(test_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=256).to(model.device)\noutputs = model(**inputs)\npred = outputs.logits.argmax(dim=-1).item()\nprint(\"Predicted label:\", pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T15:01:55.065996Z","iopub.execute_input":"2025-09-13T15:01:55.066356Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/3040 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"794a7c0635df4e2a8f1319b331b93040"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3040 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d421c607dd514c95ad6d21b6572d2743"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='26' max='456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 26/456 09:57 < 2:58:32, 0.04 it/s, Epoch 0.16/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null}]}